{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors, TfidfModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/users/kostadin.mishev/phd/dataset/train/train.tsv\",names=[\"id\",\"sentiment\",\"a\",\"text\"],sep='\\t')\n",
    "df_dev = pd.read_csv(\"/home/users/kostadin.mishev/phd/dataset/dev/dev.tsv\",names=[\"id\",\"sentiment\",\"a\",\"text\"],sep='\\t')\n",
    "train_text = df_train['text'].values\n",
    "test_text = df_dev['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/users/kostadin.mishev/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "Y_train = df_train['sentiment'].values\n",
    "Y_dev = df_dev['sentiment'].values\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train,2)\n",
    "Y_dev = keras.utils.to_categorical(Y_dev,2)\n",
    "\n",
    "Y_dev_labels = np.argmax(Y_dev,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-916a21337ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glove-wiki-gigaword-200\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gensim-data/glove-wiki-gigaword-200/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-200'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-200.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word2vec_model = api.load(\"glove-wiki-gigaword-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"/home/users/kostadin.mishev/phd/finsent/doc2vec/enwiki_dbow/doc2vec.bin\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for text in train_text:\n",
    "    X_train.append(model.infer_vector(text.split()))\n",
    "X_dev = []\n",
    "for text in test_text:\n",
    "    X_dev.append(model.infer_vector(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.asarray(X_train)\n",
    "X_dev = np.asarray(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_labels = np.argmax(Y_train,axis=1)\n",
    "Y_dev_labels = np.argmax(Y_dev,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025\n",
      "73\n",
      "211\n",
      "8\n",
      "146\n",
      "0.382240534018029\n",
      "\n",
      "0.025\n",
      "100\n",
      "201\n",
      "18\n",
      "119\n",
      "0.42198582191621686\n",
      "\n",
      "0.1\n",
      "137\n",
      "185\n",
      "34\n",
      "82\n",
      "0.48204051173447887\n",
      "\n",
      "0.25\n",
      "145\n",
      "183\n",
      "36\n",
      "74\n",
      "0.5053830229776322\n",
      "\n",
      "1\n",
      "149\n",
      "183\n",
      "36\n",
      "70\n",
      "0.5223147840931739\n",
      "\n",
      "10\n",
      "152\n",
      "182\n",
      "37\n",
      "67\n",
      "0.530111547606542\n",
      "\n",
      "50\n",
      "147\n",
      "177\n",
      "42\n",
      "72\n",
      "0.4840148912929297\n",
      "\n",
      "100\n",
      "145\n",
      "176\n",
      "43\n",
      "74\n",
      "0.47049091609473137\n",
      "\n",
      "150\n",
      "145\n",
      "174\n",
      "45\n",
      "74\n",
      "0.4606778794979673\n",
      "\n",
      "200\n",
      "147\n",
      "172\n",
      "47\n",
      "72\n",
      "0.4596256127589121\n",
      "\n",
      "1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e69a5ab0b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_dev_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "for c in [0.0025,0.025,0.1,0.25,1,10,50,100,150,200,1000,2000,5000]:\n",
    "    print(c)\n",
    "    model = SVC(kernel='linear', C=c, gamma=0.001)\n",
    "    model.fit(X_train, Y_train_labels)\n",
    "    Y_pred = model.predict(X_dev)\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_dev_labels,Y_pred).ravel() \n",
    "    mcc = matthews_corrcoef(Y_dev_labels, Y_pred)\n",
    "\n",
    "    print(tp)\n",
    "    print(tn)\n",
    "    print(fp)\n",
    "    print(fn)\n",
    "    print(mcc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "163\n",
      "56\n",
      "56\n",
      "0.4885844748858447\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#Train the XGboost Model for Classification\n",
    "model1 = xgb.XGBClassifier(n_estimators=1000, max_depth=8, learning_rate=0.01)\n",
    "\n",
    "xgb_model = model1.fit(X_train, Y_train_labels)\n",
    "\n",
    "Y_pred = xgb_model.predict(X_dev)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_dev_labels,Y_pred).ravel() \n",
    "mcc = matthews_corrcoef(Y_dev_labels, Y_pred)\n",
    "\n",
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "params = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "xgb_model= xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(xgb_model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale...t=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers;\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "np.random.seed(7)\n",
    "from tensorflow.keras import layers;\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "file_path = \"./Doc2Vec_MLP.hdf5\"\n",
    "ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                       save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "vector=300\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "def Doc2VecMLP(vector):\n",
    "  model_use_sent = Sequential()\n",
    "  #model_use_sent.add(Dense(512, activation='relu', input_shape=(vector,)))\n",
    "  #model_use_sent.add(Dropout(0.5))\n",
    "  model_use_sent.add(Dense(128, activation='relu', input_shape=(vector,)))\n",
    "  model_use_sent.add(Dropout(0.5))\n",
    "  model_use_sent.add(Dense(32, activation='relu'))\n",
    "  model_use_sent.add(Dropout(0.5))\n",
    "  model_use_sent.add(Dense(2, activation='softmax'))\n",
    "  #model.summary()\n",
    "  optimizer = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "  model_use_sent.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # compile model with training parameters\n",
    "  return model_use_sent;\n",
    "\n",
    "def InferSentCNN(vector,num_filters):\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(num_filters, 20, activation='relu', padding='same',input_shape=(vector,1)) )\n",
    "  model.add(MaxPooling1D(2))\n",
    "  model.add(Conv1D(num_filters, 20, activation='relu', padding='same'))\n",
    "  model.add(GlobalMaxPooling1D())\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "  optimizer = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  return model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61426, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.61426 to 0.53753, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53753 to 0.50325, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50325 to 0.48392, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48392 to 0.47613, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47613\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47613 to 0.46592, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.46592\n",
      "ITERATION:0\n",
      "0.7602739726027398\n",
      "0.8031914893617021\n",
      "0.6894977168949772\n",
      "0.742014742014742\n",
      "0.5258427885764645\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46592\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46592 to 0.46090, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46090 to 0.45666, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45666\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45666 to 0.45501, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "ITERATION:1\n",
      "0.7420091324200914\n",
      "0.7324561403508771\n",
      "0.7625570776255708\n",
      "0.7472035794183446\n",
      "0.4844275057779222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "ITERATION:2\n",
      "0.776255707762557\n",
      "0.8102564102564103\n",
      "0.7214611872146118\n",
      "0.7632850241545893\n",
      "0.5558593661220083\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45501\n",
      "ITERATION:3\n",
      "0.771689497716895\n",
      "0.7793427230046949\n",
      "0.7579908675799086\n",
      "0.7685185185185185\n",
      "0.5435830431298418\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "ITERATION:4\n",
      "0.7579908675799086\n",
      "0.7729468599033816\n",
      "0.730593607305936\n",
      "0.7511737089201879\n",
      "0.5167580857740227\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45501\n",
      "ITERATION:5\n",
      "0.7579908675799086\n",
      "0.7579908675799086\n",
      "0.7579908675799086\n",
      "0.7579908675799086\n",
      "0.5159817351598174\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45501\n",
      "ITERATION:6\n",
      "0.7602739726027398\n",
      "0.8097826086956522\n",
      "0.680365296803653\n",
      "0.739454094292804\n",
      "0.5273258744688015\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "ITERATION:7\n",
      "0.7625570776255708\n",
      "0.7725118483412322\n",
      "0.7442922374429224\n",
      "0.758139534883721\n",
      "0.5254648670588195\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "ITERATION:8\n",
      "0.7831050228310502\n",
      "0.7952380952380952\n",
      "0.7625570776255708\n",
      "0.7785547785547785\n",
      "0.5666887803439845\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45501\n",
      "ITERATION:9\n",
      "0.7625570776255708\n",
      "0.7777777777777778\n",
      "0.7351598173515982\n",
      "0.755868544600939\n",
      "0.5259042465841824\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45501\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45501 to 0.45476, saving model to ./Doc2Vec_MLP.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "ITERATION:10\n",
      "0.7671232876712328\n",
      "0.7969543147208121\n",
      "0.7168949771689498\n",
      "0.7548076923076922\n",
      "0.5369628345263119\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "ITERATION:11\n",
      "0.7648401826484018\n",
      "0.8052631578947368\n",
      "0.6986301369863014\n",
      "0.748166259168704\n",
      "0.534386340217642\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "ITERATION:12\n",
      "0.773972602739726\n",
      "0.8571428571428571\n",
      "0.6575342465753424\n",
      "0.7441860465116279\n",
      "0.563436169819011\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "ITERATION:13\n",
      "0.7648401826484018\n",
      "0.7685185185185185\n",
      "0.7579908675799086\n",
      "0.7632183908045977\n",
      "0.5297300702061513\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "ITERATION:14\n",
      "0.7420091324200914\n",
      "0.740909090909091\n",
      "0.7442922374429224\n",
      "0.7425968109339408\n",
      "0.48402331087585654\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "ITERATION:15\n",
      "0.7648401826484018\n",
      "0.8152173913043478\n",
      "0.684931506849315\n",
      "0.7444168734491314\n",
      "0.5365772055998331\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "ITERATION:16\n",
      "0.7579908675799086\n",
      "0.7445887445887446\n",
      "0.7853881278538812\n",
      "0.7644444444444445\n",
      "0.5167580857740227\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "ITERATION:17\n",
      "0.7648401826484018\n",
      "0.7589285714285714\n",
      "0.776255707762557\n",
      "0.7674943566591421\n",
      "0.5298184690503555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.45476\n",
      "ITERATION:18\n",
      "0.769406392694064\n",
      "0.797979797979798\n",
      "0.7214611872146118\n",
      "0.7577937649880095\n",
      "0.5413071845204606\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 42,722\n",
      "Trainable params: 42,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.45476\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45476\n",
      "ITERATION:19\n",
      "0.7557077625570776\n",
      "0.75\n",
      "0.7671232876712328\n",
      "0.7584650112866816\n",
      "0.5115488666693088\n"
     ]
    }
   ],
   "source": [
    "mcc=list()\n",
    "tp=list()\n",
    "tn=list()\n",
    "fp=list()\n",
    "fn=list();\n",
    "\n",
    "for i in range(20):\n",
    "  model_use_sent = Doc2VecMLP(vector)\n",
    "  model_use_sent.summary()\n",
    "  history = model_use_sent.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_dev,Y_dev), callbacks=[ckpt, early],verbose=0)\n",
    "  prediction = model_use_sent.predict(X_dev)\n",
    "\n",
    "  Y_pred = np.argmax(prediction,axis=1)\n",
    "  tn_, fp_, fn_, tp_ = confusion_matrix(Y_dev_labels,Y_pred).ravel() \n",
    "  mcc_ = matthews_corrcoef(Y_dev_labels, Y_pred)\n",
    "  tp.append(tp_)\n",
    "  tn.append(tn_)\n",
    "  fp.append(fp_)\n",
    "  fn.append(fn_)\n",
    "  mcc.append(mcc_)\n",
    "  print(\"ITERATION:\"+str(i))\n",
    "\n",
    "\n",
    "  print(accuracy_score(Y_dev_labels, Y_pred))\n",
    "  print(precision_score(Y_dev_labels, Y_pred))\n",
    "  print(recall_score(Y_dev_labels, Y_pred))\n",
    "  print(f1_score(Y_dev_labels, Y_pred))\n",
    "  print(mcc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.45\n",
      "173.75\n",
      "45.25\n",
      "58.55\n",
      "0.5286192415127409\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(tp))\n",
    "print(np.mean(tn))\n",
    "print(np.mean(fp))\n",
    "print(np.mean(fn))\n",
    "print(np.mean(mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
